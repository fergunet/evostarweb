 <?php include('header.php') ?>

        <h2>Evo<span class="red">Applications</span><h2>
   </div>

<h2>20th European Conference on the Applications of Evolutionary Computation</h2>

<!-- <?php include('common_to_all.php') ?>-->
<ul>
<li><a href="#abstracts">Accepted paper abstracts</a></li>
<!--<li><a href="#best">Best Paper Nominees</a></li> 
<li><a href="pdfs/EvoAPPS2015sessions.pdf">Download Evo<span class="red">APPS</span> programme</a></li>
<li><a href="#INDUSTRIALAPPLICATIONS">Industrial Applications Session</a></li>
<li><a href="#STOCHASTICANDDYNAMICENVIRONMENTS"> Stochastic and Dynamic Environments Session</a></li>
<li><a href="#COMPLEXSYSTEMS"> Complex Systems Session</a></li>
<li><a href="#POSTERS"> Poster Session</a></li>
<li><a href="#PATTERNRECOGNITION"> Pattern Recognition Session</a></li>
<li><a href="#GAMEAGENTS"> Game Agents Session</a></li>
<li><a href="#COMPUTERVISION"> Computer Vision Session</a></li>
<li><a href="#CONTENTGENERATIONANDLEARNINGINGAMES"> Content Generation and Learning in Games Session</a></li>
<li><a href="#COMMUNICATIONNETWORKS"> Communication Networks Session</a></li>
<li><a href="#ROBOTICS"> Robotics Session</a></li>
<li><a href="#RISKMANAGEMENTANDSECURITY"> Risk Management and Security Session</a></li>
<li><a href="#ENERGYFINANCE"> Energy/Finance Session</a></li>
<li><a href="#CONTINUOUSPARAMETEROPTIMISATION"> Continuous Parameter Optimisation Session</a></li>-->
</ul>
 <p>Evo<span class="red">Applications</span></a></span>, 
      the European Conference on the Applications of Evolutionary Computation 
      -formerly known as EvoWorkshops- brings together researchers in a variety 
      of areas of application of Evolutionary Computation and other Nature-inspired 
      techniques. </p>
    <p> <span id="logo">Evo<span class="red">Applications</span>
      invites high quality contributions for its 20th edition, which will be held 
      as part of the Evo<span class="red">Star</span>
      2017 event in Amsterdam, The Netherlands, April 2017 and co-located within Evo<span class="red">Star</span> 
      with three related conferences: <a href="cfp_eurogp.html">Euro<span class="red">GP</span></a>, <a href="cfp_evocop.html">Evo<span class="red">COP</span></a> 
      and <a href="cfp_evomusart.html">Evo<span class="red">MUSART</span></a>.<br />
      </span> </p>

      <strong><p>An extended version of the EvoAPPLICATIONS best papers will be published in a special issue of <a href="https://link.springer.com/journal/12293">Memetic Computing</a> (Impact Factor: 1.00)</p></strong>
  
    <p><span id="logo">Evo<span class="red">Applications</span>
      2017 is composed of 13 tracks, each focusing on an area of application of 
      genetic and evolutionary computation and other related Computational Intelligence 
      fields. The following tracks will be running in 2017: </span> </p>
    <span id="logo"> 

      <ul>
     <li><a href="cfp_evobafin.php">Evo<span class="red">BAFIN</span></a> - Natural Computing Methods in Business Analytics and Finance</li>
         <li><a href="cfp_evobio.php">Evo<span class="red">BIO</span></a> 
        - Evolutionary Computation, Machine Learning and Data Mining in Computational Biology</li>
         <li><a href="cfp_evocomnet.php">Evo<span class="red">COMNET</span></a> - 
        Nature-inspired Techniques for Communication Networks and other Parallel 
        and Distributed Systems.</li>
      <li><a href="cfp_evocomplex.php">Evo<span class="red">COMPLEX</span></a> 
        - Evolutionary Algorithms and Complex Systems</li>
      <li><a href="cfp_evoenergy.php">Evo<span class="red">ENERGY</span></a> - 
        Evolutionary Algorithms in Energy Applications</li>
      
      <li><a href="cfp_evogames.php">Evo<span class="red">GAMES</span></a> - Bio-inspired 
        Algorithms in Games</li>
      <li><a href="cfp_evoiasp.php">Evo<span class="red">IASP</span></a> - Evolutionary 
        Computation in Image Analysis, Signal Processing and Pattern Recognition</li>
      <li><a href="cfp_evoindustry.php">Evo<span class="red">INDUSTRY</span></a> 
        - Evolutionary and Bio-Inspired Computational Techniques within Real-World 
        Industrial and Commercial Environments.</li>

      <li><a href="cfp_evoknow.php">Evo<span class="red">KNOW</span></a> 
        - Knowledge Incorporation in Evolutionary Computation.</li>
      <li><a href="cfp_evonum.php">Evo<span class="red">NUM</span></a> - Bio-inspired 
        algorithms for continuous parameter optimisation</li>
      <li><a href="cfp_evopar.php">Evo<span class="red">PAR</span></a> - Parallel 
        Architectures and Distributed Infrastructures</li>
      <!--<li><a href="cfp_evorisk.php">Evo<span class="red">RISK</span></a> - Computational 
        Intelligence for Risk Management, Security and Defence Applications</li>-->
      <li><a href="cfp_evoset.php">Evo<span class="red">SET</span></a> - Nature-inspired algorithms in Software Engineering and Testing</li>
      <li><a href="cfp_evorobot.php">Evo<span class="red">ROBOT</span></a> - Evolutionary 
        Robotics</li>
      <li><a href="cfp_evostoc.php">Evo<span class="red">STOC</span></a> - Evolutionary 
        Algorithms in Stochastic and Dynamic Environments</li>
    </ul>
    <p>Join the the EVOstar group on LinkedIn for more details and updates.</p>
    </span> 
    
   

 
    <h3> FURTHER INFORMATION </h3>
    <p> Further information on the conference and co-located events can be <br />
      found in: <a href="http://www.evostar.org/">http://www.evostar.org</a> </p>
    <span id="logo"> 
    <h3>Evo<span class="red">Applications</span> 
      coordinator</h3>
    <blockquote> 
      <p><span><strong>Giovanni Squillero</strong> <br />
        Politecnico di Torino, Italy <br />
        <em>giovanni.squillero@polito.it </em></span></p>
    </blockquote>

<h3>Evo<span class="red">Applications</span> Publication Chair</h3>
    <blockquote> 
      <p><span><strong>Kevin Sim</strong> <br />
        Edinburgh Napier University, UK <br />
        <em>K.Sim(at)napier.ac.uk</em></span></p>
    </blockquote>




<a name="abstracts"></a>
<h2>Evo<span class="red">APPS</span> Abstracts</h2>


</p><p><strong>Title: Minimization of Systemic Risk for Directed Network Using Genetic Algorithm
</strong><br/><strong>Author:</strong>  Wenshuo Guo, Kwok Yip Szeto
</strong><br/><strong>Abstract:</strong> In directed networks, flow dynamics may lead to cascade failures due to node and link removal. The systemic risk in financial systems follows similar mechanism, where banks are connected by interbank linkages with money transfers. A mathematical model of the banking network is used to investigate the relationships between the cascade dynamics and key parameters determining the banking network structure, including the connectivity, the bank's capitalization, and the size of interbank exposure, based on analytical calculation and numerical simulation. To optimize the network topology for the minimization of systemic risk, genetic algorithm is applied to evolve the network. It is observed that the systemic risk of financial system could be decreased by increasing the degree variance of the associated network. This could be useful for financial risk management, with possible applications to other physical systems such as ecological web, where the network stability is also an important issue.



</p><p><strong>Title: Pricing Rainfall Based Futures Using Genetic Programming
</strong><br/><strong>Author:</strong>  Sam Cramer, Michael Kampouridis, Alex Freitas, Antonis Alexandridis
</strong><br/><strong>Abstract:</strong> Rainfall derivatives are in their infancy since starting trading on the Chicago Mercentile Exchange (CME) since 2011. Being a relatively new class of financial instruments there is no generally recognised pricing framework used within the literature. In this paper, we propose a novel framework for pricing contracts using Genetic Programming (GP). Our novel framework requires generating a risk-neutral density of our rainfall predictions generated by GP supported by Markov chain Monte Carlo and Esscher transform. Moreover, instead of having a single rainfall model for all contracts, we propose having a separate rainfall model for each contract. We compare our novel framework with and without our proposed contract-specific models for pricing against the pricing performance of the two most commonly used methods, namely Markov chain extended with rainfall prediction (MCRP), and burn analysis (BA) across contracts available on the CME. Our goal is twofold, (i) to show that by improving the predictive accuracy of the rainfall process, the accuracy of pricing also increases. (ii) contract-specific models can further improve the pricing accuracy. Results show that both of the above goals are met, as GP is capable of pricing rainfall futures contracts closer to the CME than MCRP and BA. This shows that our novel framework for using GP is successful, which is a significant step forward in pricing rainfall derivatives.



</p><p><strong>Title: Dynamic Portfolio Optimization in Ultra-High Frequency Environment
</strong><br/><strong>Author:</strong>  Patryk Filipiak, Piotr Lipinski
</strong><br/><strong>Abstract:</strong> This paper concerns the problem of portfolio optimization in the context of ultra-high frequency environment with dynamic and frequent changes in statistics of financial assets. It aims at providing Pareto fronts of optimal portfolios and updating them when estimated return rates or risks of financial assets change. The problem is defined in terms of dynamic optimization and solved online with a proposed evolutionary algorithm. Experiments concern ultra-high frequency time series coming from the London Stock Exchange Rebuilt Order Book database and the FTSE100 index.


</p><p><strong>Title: Integration of Reaction Kinetics Theory and Gene Expression Programming to Infer Reaction Mechanism
</strong><br/><strong>Author:</strong>  Jason White, Ranjan Srivastava
</strong><br/><strong>Abstract:</strong> Mechanistic mathematical models of biomolecular systems have been used to de-scribe biological phenomena in the hope that one day these models may be used to enhance our fundamental understanding of these phenomena, as well as to op-timize and engineer biological systems. An evolutionary algorithm capable of formulating mass action kinetic models of biological systems from time series da-ta sets was developed for a system of n-species.  The strategy involved using a gene expression programming (GEP) based approach and heuristics based on chemical kinetic theory.  The resulting algorithm was successfully validated by recapitulating a nonlinear model of viral dynamics using only a ìnoisyî set of time series data.  While the system analyzed for this proof-of-principle study was relatively small, the approach presented here is easily parallelizable making it amenable for use with larger systems.  Additionally, greater efficiencies may po-tentially be realized by further taking advantage of the problem domain along with future breakthroughs in computing power and algorithmic advances.



</p><p><strong>Title: De Novo DNA Assembly with a Genetic Algorithm Finds Accurate Genomes Even with Suboptimal Fitness
</strong><br/><strong>Author:</strong>  Doina Bucur
</strong><br/><strong>Abstract:</strong> We design an evolutionary heuristic for the combinatorial problem of de-novo DNA assembly with short, overlapping, accurately sequenced single DNA reads of uniform length, from both strands of a genome without long repeated sequences. The representation of a candidate solution is a novel segmented permutation: an ordering of DNA reads into contigs, and of contigs into a DNA scaffold. Mutation and crossover operators work at the contig level. The fitness function minimizes the total length of scaffold (i.e., the sum of the length of the overlapped contigs) and the number of contigs on the scaffold. We evaluate the algorithm with read libraries uniformly sampled from genomes 3835 to 48502 base pairs long, with genome coverage between 5 and 7, and verify the biological accuracy of the scaffolds obtained by comparing them against reference genomes. We find the correct genome as a contig string on the DNA scaffold in over 95% of all assembly runs. For the smaller read sets, the scaffold obtained consists of only the correct contig; for the larger read libraries, the fitness of the solution is suboptimal, with chaff contigs present; however, a simple post-processing step can realign the chaff onto the correct genome. The results support the idea that this heuristic can be used for consensus building in de-novo assembly.



</p><p><strong>Title: EVE: Cloud-based Annotation of Human Genetic Variants
</strong><br/><strong>Author:</strong>  Brian Cole, Jason Moore
</strong><br/><strong>Abstract:</strong> Annotation of human genetic variants enables genotype-phenotype association studies at the gene, pathway, and tissue level. ¬†Annotation results are difficult to reproduce across study sites due to shifting software versions and a lack of a unified hardware interface between study sites. ¬†Cloud computing offers a promising solution by integrating hardware and software into reproducible virtual appliances which may be utilized on-demand and shared across institutions. We developed ENSEMBL VEP on EC2 (EVE), a cloud-based virtual appliance for annotation of human genetic variants built around the ENSEMBL Variant Effect Predictor. We integrated virtual hardware infrastructure, open-source software, and publicly available genomic datasets to provide annotation capability for genetic variants in the context of genes/transcripts, Gene Ontology pathways, tissue-specific expression from the Gene Expression Atlas, miRNA annotations, minor allele frequencies from the 1000 Genomes Project and the Exome Aggregation Consortium, and deleteriousness scores from Combined Annotation Dependent Depletion. ¬†We demonstrate the utility of EVE by annotating the genetic variants in a case-control study of glaucoma. Cloud computing can reduce the difficulty of replicating complex software pipelines such as annotation pipelines across study sites. ¬†We provide a publicly available CloudFormation template of the EVE virtual appliance which can automatically provision and deploy a parameterized, preconfigured hardware/software stack ready for annotation of human genetic variants (github.com/epistasislab/EVE). ¬†This approach offers increased reproducibility in human genetic studies by providing a unified appliance to researchers across the world.



</p><p><strong>Title: Improving the reproducibility of genetic association results using genotype resampling methods
</strong><br/><strong>Author:</strong>  Elizabeth Piette, Jason Moore
</strong><br/><strong>Abstract:</strong> Replication may be an inadequate gold standard for substantiating the significance of results from genome-wide association studies (GWAS). Successful replication provides evidence supporting true results and against spurious findings, but vari-ous population attributes contribute to observed significance of a genetic effect. We hypothesize that failure to replicate an interaction observed to be significant in a GWAS of one population in a second population is sometimes attributable to differences in minor allele frequencies, and resampling the replication dataset by genotype to match the minor allele frequencies of the discovery data can improve estimates of the interaction significance. We show via simulation that resampling of the replication data produced results more concordant with the discovery find-ings. We recommend that failure to replicate GWAS results should not immedi-ately be considered to refute previously-observed findings and conversely that replication does not guarantee significance, and suggest that datasets be compared more critically in biological context.


</p><p><strong>Title: Objective Assessment of Cognitive Impairment in Parkinson's Disease using Evolutionary Algorithm
</strong><br/><strong>Author:</strong>  Chiara Picardi, Jeremy Cosgrove, Stephen L. Smith, Stuart Jamieson, Jane E. Alty
</strong><br/><strong>Abstract:</strong> Parkinson's disease (PD) is a common and disabling condition without cure. An early and accurate diagnosis is important for monitoring the disease and managing symptoms.  Over time, the majority of patients with PD develop cognitive impairment, which is diagnosed using global tests of cognitive function or more detailed neuropsychological assessment. This paper presents an approach to detect PD and to discriminate different degrees of PD cognitive impairment in an objective way, considering a simple and non-invasive ‚Äúreach and grasp‚Ä? task performed with the patient wearing sensor-enabled data gloves recording movements in real-time.  The PD patients comprised three subgroups:  22 PD patients with normal cognition (PD-NC), 23 PD patients with mild cognitive impairment (PD-MCI) and 10 PD patients with dementia (PDD).  In addition, 30 age-matched healthy subjects (Controls) were also measured. From the experimental data, 25 kinematic features were extracted with the aim of generating a classifier that is able to discriminate not only between Controls and PD patients, but also between the PD cognitive subgroups.  The technique used to find the best classifier was an Evolutionary Algorithm - Cartesian Genetic Programming (CGP), and this is compared with Support Vector Machine (SVM) and Artificial Neural Network (ANN).  In all cases, the CGP classifiers were comparable with SVM and ANN, and in some cases performed better. The results are promising and show both the potential of the computed features and of CGP in aiding PD diagnosis.



</p><p><strong>Title: Characterising the influence of rule-based knowledge representations in biological knowledge extraction from transcriptomics data
</strong><br/><strong>Author:</strong>  Simon Baron, Nicola Lazzarini, Jaume Bacardit
</strong><br/><strong>Abstract:</strong> Currently, there is a wealth of biotechnologies (e.g. sequencing, proteomics, lipidomics) able to generate a broad range of data types out of biological samples. However,  the knowledge gained from such data sources is constrained by the limitations of the analytics techniques. The state-of-the-art machine learning algorithms are able to  capture complex patterns with high prediction capacity. However, often it is very difficult if not impossible to extract human-understandable knowledge out of these  patterns. In recent years evolutionary machine learning techniques have shown that they are competent methods for biological/biomedical data analytics. They are able to  generate interpretable prediction models and, beyond just prediction models, they are able to extract useful knowledge in the form of biomarkers or biological networks. The focus of this paper is to thoroughly characterise the impact that a core component of the evolutionary machine learning process, its knowledge representations, has in  the process of extracting biologically-useful knowledge out of transcriptomics datasets. Using the FuNeL evolutionary machine learning-based network inference method, we  evaluate several variants of rule knowledge representations on a range of transcriptomics datasets to quantify the volume and complementarity of the knowledge that each of  them can extract. Overall we show that knowledge representations, often considered a minor detail, greatly impact on the downstream biological knowledge extraction process.



</p><p><strong>Title: Enhancing Grammatical Evolution through Data Augmentation: Application to Blood Glucose Forecasting
</strong><br/><strong>Author:</strong>  Jose Manuel Velasco, Oscar Garnica, Sergio Contador, Jose Manuel Colmenar, Esther Maqueda, Marta Botella, Juan Lanchares, Jose Ignacio HIdalgo
</strong><br/><strong>Abstract:</strong> Currently, Diabetes Mellitus Type 1 patients are waiting hopefully for the arrival of the Artificial Pancreas (AP) in a near future. AP systems will control the blood glucose of people that suffer the disease, improving their lives and reducing the risks they face everyday. At the core of the AP, an algorithm will forecast future glucose levels and estimate insulin bolus sizes. Grammatical Evolution (GE) has been proved as a suitable algorithm for predicting glucose levels. Nevertheless, one the main obstacles that researches have found for training the GE models is the lack of significant amounts of data. As in many other fields in medicine, the collection of data from real patients is very complex. In this paper, we propose a data augmentation algorithm that generates synthetic glucose time series from real data. The synthetic time series can be used to train a unique GE model or to produce several GE models that work together in a combining system. Our experimental results show that, in a scarce data context, Grammatical Evolution models can get more accurate and robust predictions using data augmentation.



</p><p><strong>Title:  Genetic programming representations for multi-dimensional feature learning in biomedical classification
</strong><br/><strong>Author:</strong>  William La Cava, Sara Silva, Lee Spector, Leonardo Vanneschi, Jason Moore
</strong><br/><strong>Abstract:</strong> We present a new classification method that uses genetic programming (GP) to evolve feature transformations for a deterministic, distanced-based classifier. This method, called M4GP, differs from common approaches to classifier representation in GP in that it does not enforce arbitrary decision boundaries and it allows individuals to produce multiple outputs via a stack-based GP system. In comparison to typical methods of classification, M4GP can be advantageous in its ability to produce readable models. We conduct a comprehensive study of M4GP, first in comparison to other GP classifiers, and then in comparison to six common machine learning classifiers. We conduct full hyper-parameter optimization for all of the methods on a suite of 16 biomedical data sets, ranging in size and difficulty. The results indicate that M4GP outperforms other GP methods for classification. M4GP performs competitively with other machine learning methods in terms of the accuracy of the produced models for most problems. M4GP also exhibits the ability to detect epistatic interactions better than the other methods.


</p><p><strong>Title: Meta-heuristically Seeded Genetic Algorithm for Independent Job Scheduling in Grid Computing
</strong><br/><strong>Author:</strong>  Muhanad Younis, Shengxiang Yang, Benjamin Passow
</strong><br/><strong>Abstract:</strong> Grid computing is an infrastructure which connects geographically distributed computers owned by various organizations allowing their resources, such as computational power and storage capabilities, to be shared, selected, and aggregated. Job scheduling problem is one of the most difficult tasks in grid computing systems. To solve this problem efficiently, new methods are required. In this paper, a seeded genetic algorithm is proposed which uses a meta-heuristic algorithm to generate its initial population. To evaluate the performance of the proposed method in terms of minimizing the makespan, the Expected Time to Compute (ETC) simulation model is used to carry out a number of experiments. The results show that the proposed algorithm performs better than other selected techniques.



</p><p><strong>Title: Analysis of Average Communicability in Complex Networks
</strong><br/><strong>Author:</strong>  Qi Bu, Kwok Yip Szeto
</strong><br/><strong>Abstract:</strong> The average communicability of a complex network is an important measure of the efficiency of information exchange in the entire network. The optimization of average communicability is a significant problem in network design for various applications in science and engineering. Since the search of the topology that achieves the highest average communicability is a very difficult problem due to the enormous size of the solution space, genetic algorithm is a good choice for search. From numerical simulation, we discover a positive correlation between the variance of the degree distribution with the average communicability of the network. This correlation is then proven mathematically, with applications to the comparison for the average communicability of two networks with the same number of nodes and links using the largest eigenvalues of their adjacency matrices.


</p><p><strong>Title: Configuring Dynamic Heterogeneous Wireless Communications Networks using a Customised Genetic Algorithm
</strong><br/><strong>Author:</strong>  David Lynch, Michael Fenton, Stepan Kucera, Holger Claussen, Michael O'Neill
</strong><br/><strong>Abstract:</strong> Wireless traffic is surging due to the prevalence of smart devices, rising demand for multimedia content and the advent of the "Internet of Things''. Network operators are deploying Small Cells alongside existing Macro Cells in order to satisfy demand during this era of exponential growth. Such Heterogeneous Networks (HetNets) are highly spectrally efficient because both cell tiers transmit using the same scarce and expensive bandwidth. However, load balancing and cross-tier interference issues constrain cell-edge rates in co-channel operation. Capacity can be increased by intelligently configuring Small Cell powers and biases, and the muting cycles of Macro Cells. This paper presents a customised Genetic Algorithm (GA) for reconfiguring HetNets. The GA converges within minutes so tailored settings can be pushed to cells in real time. The proposed GA lifts cell-edge (2.5'th percentile) rates by 32% over a non-adaptive baseline that is used in practice. HetNets are highly dynamic environments. However, customers tend to cluster in hotspots which arise at predictable locations over the course of a typical day. An explicit memory of previously evolved solutions is maintained and used to seed fresh runs. System level simulations show that the 2.5'th percentile rates are boosted to 36% over baseline when prior knowledge is utilised. 


</p><p><strong>Title: Multi-Objective Evolutionary Algorithms for Influence Maximization in Social Networks
</strong><br/><strong>Author:</strong>  Doina Bucur, Giovanni Iacca, Andrea Marcelli, Giovanni Squillero, Alberto Tonda
</strong><br/><strong>Abstract:</strong> As the pervasiveness of social networks increases, new NP-hard related problems become interesting for the optimization community. The objective of \emph{influence maximization} is to contact the largest possible number of nodes in a network, starting from a small set of seed nodes, and assuming a model for information propagation. This problem is of utmost practical importance for applications ranging from social studies to marketing. The influence maximization problem is typically formulated assuming that the number of the seed nodes is a parameter. Differently, in this paper, we choose to formulate it in a multi-objective fashion, considering the minimization of the number of seed nodes among the goals, and we tackle it with an evolutionary approach. As a result, we are able to identify sets of seed nodes of different size that spread influence the best, providing factual data to trade-off costs with quality of the result. The methodology is tested on two real-world case studies, using two different influence propagation models, and compared against state-of-the-art heuristic algorithms. The results show that the proposed approach is almost always able to outperform the heuristics.



</p><p><strong>Title: A fast ILP-based Heuristic for the robust design of Body Wireless Sensor Networks
</strong><br/><strong>Author:</strong>  Fabio D'Andreagiovanni, Antonella Nardin, Enrico Natalizio
We consider the problem of optimally designing a body wireless sensor network, while taking into account the uncertainty of data generation of biosensors. Since the related min-max robustness Integer Linear Programming (ILP) problem can be difficult to solve even for state-of-the-art commercial optimization solvers, we propose an original heuristic for its solution. The heuristic combines deterministic and probabilistic variable fixing strategies, guided by the information coming from strengthened linear relaxations of the ILP robust model, and includes a very large neighborhood search for reparation and improvement of generated solutions, formulated as an ILP problem solved exactly. Computational tests on realistic instances show that our heuristic finds solutions of much higher quality than a state-of-the-art solver and than an effective benchmark heuristic.


</p><p><strong>Title: Lamarckian and Lifelong Memetic Search in Agent-based Computing
</strong><br/><strong>Author:</strong>  Wojciech Korczynski, Marek Kisiel-Dorohinicki, Aleksander Byrski
</strong><br/><strong>Abstract:</strong> Memetic algorithms when used with care can help in balancing exploitation and exploration of the metaheuristics, without the overhead measured by the rapidly increased number of function fitness calls. The paper tackles such balancing of use of metaheuristics in an agent-oriented setting. In particular, application of local search during a computing agent's life is researched. The results shown for selected benchmark functions are presented along with necessary statistic testing.



</p><p><strong>Title:  Two-phase strategy managing insensitivity in global optimization
</strong><br/><strong>Author:</strong>  Jakub Sawicki, Maciej Smo\l{}ka, Marcin \L{}o\'s, Robert Schaefer, Piotr Faliszewski
</strong><br/><strong>Abstract:</strong> Solving ill-posed continuous, global optimization problems remains challenging. For example, there are no well-established methods for handling objective insensitivity in the neighborhood of solutions, which appears in many important applications, e.g., in non-invasive tumor tissue diagnosis or geophysical exploration. The paper presents a~complex metaheuristic that identifies regions of objective function's insensitivity (plateaus). The strategy is composed of a~multi-deme hierarchic memetic strategy coupled with random sample clustering, cluster integration, and special kind of multiwinner selection that allows to breed the demes and cover each plateau separately. We test the method on benchmarks with multiple non-convex plateaus and evaluate how well the plateaus are covered.



</p><p><strong>Title: Avenues for the Use of Multi–State Cellular Automata
</strong><br/><strong>Author:</strong>  Laura Diosan, Anca Andreica, Irina Voiculescu, Imre Boros
</strong><br/><strong>Abstract:</strong> The majority of Cellular Automata (CA) described in the literature are binary or three--state. While several abstractions are possible to generalise to more than three states, only a negligible number of multi--state CA rules exist with concrete practical applications. This paper proposes a generic rule for multi--state CA. The rule allows for any number of states, and allows for the states are semantically related.  The rule is illustrated on the concrete example of image segmentation, where the CA agents are pixels in an image, and their states are the pixels' greyscale values. We investigate in detail the proposed rule and some of its variations, and we also compare its effectiveness against its closest relative, the existing GH automaton.  We apply the proposed methods to both synthetic and real--world images, evaluating the results with a variety of measures. The experimental results demonstrate that our proposed method can segment images accurately and effectively.



</p><p><strong>Title:  Local Misfit Approximation in Memetic Solving of Ill-posed Inverse Problems
</strong><br/><strong>Author:</strong>  Marcin ?o?, Robert Schaefer, Jakub Sawicki, Maciej Smo?ka
</strong><br/><strong>Abstract:</strong> The approximation of the objective function is a well known method of speeding up optimization process, especially if the objective evaluation is costly.  This is the case of inverse parametric problems formulated as global optimization ones, in which we recover partial differential equation parameters by minimizing the misfit between its measured and simulated solutions.  Typically, the approximation used to build the surrogate objective is rough but globally applicable in the whole admissible domain.  The authors try to carry out a different task of detailed misfit approximation in the regions of low sensitivity (plateaus).  The proposed complex method consists of independent C0 Lagrange approximation of the misfit and its gradient, based on the nodes obtained during the dedicated memetic process, and the subsequent projection of the obtained components (single or both) on the space of B-splines.  The resulting approximation is globally C1, which allows us to use fast gradient-based local optimization methods. Another goal attained in this way is the estimation of the shape of plateau as an appropriate level set of the approximated objective.  The proposed strategy can be applied for solving ill-conditioned real world inverse problems, e.g., appearing in the oil deposit investigation.  We show the results of preliminary tests of the method on two benchmarks featuring convex and non-convex U-shaped plateaus.



</p><p><strong>Title: The Two Regimes of Neutral Evolution: Localization on Hubs and Delocalized Diffusion
</strong><br/><strong>Author:</strong>  David Shorten, Geoff Nitschke 
</strong><br/><strong>Abstract:</strong> It has been argued that much of evolution takes place in the absence of fitness gradients. Such periods of evolution can be analysed by examining the mutational network formed by sequences of equal fitness, that is the neutral network. It has been demonstrated that, in large populations under a high mutation rate, the population distribution over the neutral network and average mutational robustness are given by the principle eigenvector and eigenvalue, respectively, of the network's adjacency matrix. However, little progress has been made towards understanding the manner in which the topology of the neutral network influences the resulting population distribution and robustness. In this work, we build on recent results from spectral graph theory and utilize numerical methods to demonstrate that there exist two regimes of behaviour: convergence on hubs and diffusion over the network. We also derive approximations for the population's behaviour under these regimes. This challenges the widespread assumption that neutral evolution always leads to exploration of the neutral network and elucidates the conditions which result in the evolution of robust organisms.


</p><p><strong>Title:  Adaptive Batteries Exploiting On-line Steady-State Evolution Strategy
</strong><br/><strong>Author:</strong>  Edoardo Fadda, Guido Perboli, Giovanni Squillero
</strong><br/><strong>Abstract:</strong> In energy distribution systems, uncertainty is the major single cause of power outages. In this paper, we consider the usage of electric batteries in order to mitigate it. We describe an intelligent battery able to maximize its own lifetime while guaranteeing to satisfy all the electric demand peaks. The battery exploits a customized steady-state evolution strategy to dynamically adapt its recharge strategy to changing environments. Experimental results on both synthetic and real data demonstrate the efficacy of the proposed solution.



</p><p><strong>Title:  Hybrid Multi-Ensemble Scheduling
</strong><br/><strong>Author:</strong>  Joerg Bremer, Sebastian Lehnhoff
</strong><br/><strong>Abstract:</strong> A steadily increasing pervasion of the electrical distribution grid with rather small renewable energy resources imposes fluctuating and hardly predictable feed-in, a partly reverse load flow and demands new predictive load planning strategies. For predictive scheduling with high penetration of renewable energy resources, agent-based approaches using classifier-based decoders for modeling individual flexibilities have shown good performance. On the other hand, such decoder-based methods are currently designed for single entities and not able to cope with ensembles of energy resources. Combining training sets sampled from individually modeled energy units, results in folded distributions with unfavorable properties for training a decoder. Nevertheless, this happens to be a quite frequent use case, e.g. when a hotel, a small business, a school or similar with an ensemble of co-generation, heat pump, solar power, and controllable consumers wants to take part in decentralized predictive scheduling. In this paper, we propose an extension to an established agent approach for scheduling individual single energy units by extending the agents' decision routine with a covariance matrix adaption evolution strategy that is hybridized with decoders. In this way, locally managed ensembles of energy units can be included. We show the applicability of our approach by conducting several simulation studies.

_____

paper55,Page 354,EvoGAMES

</p><p><strong>Title: Driving in TORCS using modular fuzzy controllers
</strong><br/><strong>Author:</strong>  Mohammed SALEM, Antonio Miguel MORA, Juan Julian MERELO, Pablo García-Sánchez
</strong><br/><strong>Abstract:</strong> When driving a car it is essential to take into account all possible factors; even more so when, like in the TORCS simulated race game, the objective is not only to avoid collisions, but also to win the race within a limited budget. In this paper, we present the design of an autonomous driver for racing car in a simulated race. Unlike previous controllers, that only used fuzzy logic approaches for either acceleration or steering, the proposed driver uses simultaneously two fuzzy controllers for steering and computing the target speed of the car at every moment of the race. They use the track border sensors as inputs and besides, for enhanced safety, it has also taken into account the relative position of the other competitors. The proposed fuzzy driver is evaluated in practise and timed races giving good results across a wide variety of racing tracks, mainly those that have many turning points.



</p><p><strong>Title:  Automated Game Balancing in Ms Pacman and StarCraft using Evolutionary Algorithms
</strong><br/><strong>Author:</strong>  Mihail Morosan, Riccardo Poli
</strong><br/><strong>Abstract:</strong> Games, particularly online games, have an ongoing requirement to exhibit the ability to react to player behaviour and change their mechanics and available tools to keep their audience both entertained and feeling that their strategic choices and in-game decisions have value. Game designers invest time both gathering data and analysing it to introduce minor changes that bring their game closer to a state of balance, a task with a lot of potential that has recently come to the attention of researchers. This paper first provides a method for automating the process of finding the best game parameters to reduce the difficulty of Ms PacMan  through the use of evolutionary algorithms and then applies the same method to a much more complex and commercially successful PC game, StarCraft, to curb the prowess of a dominant strategy. Results show both significant promise and several avenues for future improvement that may lead to a useful balancing tool for the games industry.



</p><p><strong>Title: Evolving game-specific UCB alternatives for General Video Game Playing
</strong><br/><strong>Author:</strong>  Ivan Bravi, Ahmed Khalifa, Christoffer Holmgård, Julian Togelius
</strong><br/><strong>Abstract:</strong> At the core of the most popular version of the Monte Carlo Tree Search (MCTS) algorithm is the UCB1 (Upper Confidence Bound) equation. This equation decides which node to explore next, and therefore shapes the behavior of the search process. If the UCB1 equation is replaced with another equation, the behavior of the MCTS algorithm changes, which might increase its performance on certain problems (and decrease it on others). In this paper, we use genetic programming to evolve replacements to the UCB1 equation targeted at playing individual games in the General Video Game AI (GVGAI) Framework. Each equation is evolved to maximize playing strength in a single game, but is then also tested on all other games in our test set. For every game included in the experiments, we found a UCB replacement that performs significantly better than standard UCB1. Additionally, evolved UCB replacements also tend to improve performance in some GVGAI games for which they are not evolved, showing that improvements generalize across games to clusters of games with similar game mechanics or algorithmic performance. Such an evolved portfolio of UCB variations could be useful for a hyper-heuristic game-playing agent, allowing it to select the most appropriate heuristics for particular games or problems in general. 


</p><p><strong>Title: Relief Camp Manager: A Serious Game using the World Health Organization's Relief Camp Guidelines
</strong><br/><strong>Author:</strong>  Hamna Aslam, Anton Sidorov, Nikita Bogomazov, Fedore Berezyuk, Joseph Alexander Brown
</strong><br/><strong>Abstract:</strong> Emergency management plans rely on training in order to provide support to first responders, government planners, and affected persons in potential disaster zone.  Serious Games have proved to be useful in capturing and invoking people's attention and emergency management education is also being delivered through games. The paper presents a relief camp game developed using the figures from World Health Organization's (WHO) report on water, sanitation and hygiene guidelines in emergencies. The game play provides player an understanding of the management of relief camps by giving them a supervisory role to design and organize camp areas. It also encourages players to introduce their own ideas in setting up relief camps. The player is competing against  evolutionary computation algorithm. The aims are to create awareness about relief camp management strategies and improving the present approaches for better plans via human competitive testing.


</p><p><strong>Title: Analyisis of Vanilla Rolling Horizon Evolution Parameters in General Video Game Playing
</strong><br/><strong>Author:</strong>  Raluca D. Gaina, Jialin Liu, Simon M. Lucas, Diego Perez-Liebana
</strong><br/><strong>Abstract:</strong> Monte Carlo Tree Search techniques have generally dominated General Video Game Playing, but recent research has started looking at Evolutionary Algorithms and their potential at matching Tree Search level of play or even outperforming these methods. Online or Rolling Horizon Evolution is one of the options available to evolve sequences of actions for planning in General Video Game Playing, but no research has been done up to date that explores the capabilities of the vanilla version of this algorithm in multiple games. This study aims to critically analyse the different configurations regarding population size and individual length in a set of $20$ games from the General Video Game AI corpus. Distinctions are made between deterministic and stochastic games, and the implications of using superior time budgets are studied. Results show that there is scope for the use of these techniques, which in some configurations outperform Monte Carlo Tree Search, and also suggest that further research in these methods could boost their performance.



</p><p><strong>Title: Darwin's Demons: Does Evolution Improve the Game?
</strong><br/><strong>Author:</strong>  Terence Soule, Barrie D. Robison, Samantha Heck, Thomas E. Haynes, David Street, Nicholas Wood
</strong><br/><strong>Abstract:</strong> It is widely assumed that evolution has the potential to make better video games. However, relatively few commercial games have been released that use evolution as a core game mechanic, and of these games only a very small sub-set have shown that evolution occurs as expected and improves game play as intended.  Thus, there remains a critical gap between studies showing the clear potential of evolution to improve video games and studies showing that evolution did improve game play in a commercially released game. We have developed Darwin's Demons, a space shooter inspired by old style arcade games, with the added feature of evolving enemies.  In August, 2016 Darwin's Demons was Green-lit for sale on Steam, a standard benchmark for commercialization of games.  In this paper we present and test four hypotheses that form the basis for the claim that evolution occurs and improves game play in Darwin's Demons. More generally, these hypotheses can be used to confirm that evolution meets the intended design goals for other evolutionary games. Our results support the hypotheses that evolution makes Darwin's Demons get progressively more difficult over the course of a game, and that the fitness function, player choices, and player strategy all affect the evolutionary trajectory during a single game.  This suggests that in Darwin's Demons, the enemies adapt to the player's decisions and strategy, making the game interesting and increasing its replayability.


</p><p><strong>Title: Evolutionary Art using the Fly Algorithm
</strong><br/><strong>Author:</strong>  Zainab Abbood, Othman Amlal, Franck Vidal
</strong><br/><strong>Abstract:</strong> This study is about Evolutionary art such as digital mosaics.The most common techniques to generate a digital mosaic effect heavily rely on Centroidal Voronoi diagrams. Our method generates artistic images as an optimisation problem without the introduction of any a priori knowledge or constraint other than the input image. We adapt a cooperative co-evolution strategy based on the Parisian evolution approach, the Fly algorithm, to produce artistic visual effects from an input image (e.g. a photograph). The primary usage of the Fly algorithm is in computer vision, especially stereo-vision in robotics. It has also been used in image reconstruction for tomography. Until now the individuals correspond to simplistic primitives: Infinitely small 3-D points. In this paper, the individuals have a much more complex representation and represent tiles in a mosaic. They have their own position, size, colour, and rotation angle. We take advantage of graphics processing units (GPUs) to generate the images using the modern OpenGL Shading Language. Different types of tiles are implemented, some with transparency, to generate different visual effects, such as digital mosaic and spray paint. A user study has been conducted to evaluate some of our results. We also compare results with those obtained with GIMP, an open-source software for image manipulation.



</p><p><strong>Title: Bagging and Feature Selection for Classification with Incomplete Data
</strong><br/><strong>Author:</strong>  Cao Truong Tran, Mengjie Zhang, Peter Andreae, Bing Xue
</strong><br/><strong>Abstract:</strong> Missing values are an unavoidable issue of many real-world datasets. Dealing with missing values is an essential requirement in classification problem, because inadequate treatment with missing values often leads to large classification errors. Some classifiers can directly work with incomplete data, but they often result in big classification errors and generate complex models. Feature selection and bagging have been successfully used to improve classification, but they are mainly applied to complete data. This paper proposes a combination of bagging and feature selection to improve classification with incomplete data. To achieve this purpose, a wrapper-based feature selection which can directly work with incomplete data is used to select suitable feature subsets for bagging. The experiments on eight incomplete datasets were designed to compare the proposed method with three other popular methods that are able to deal with incomplete data using C4.5/REPTree as classifiers and using Particle Swam Optimisation as a search technique in feature selection. Results show that the combination of bagging and feature selection can not only achieve better classification accuracy than the other methods but also generate less complex models compared to the bagging method.



</p><p><strong>Title: Surrogate-model based Particle Swarm Optimisation with Local Search for Feature Selection in Classification
</strong><br/><strong>Author:</strong>  Bach Nguyen, Bing Xue, Peter Andreae
</strong><br/><strong>Abstract:</strong> Evolutionary computation (EC) techniques have been applied widely to many problems because of their powerful search ability. However, EC based algorithms are usually computationally intensive, especially with an expensive fitness function. In order to solve this issue, many surrogate models have been proposed to reduce the computation time by approxi- mating the fitness function, but they are hardly applied to EC based fea- ture selection. This paper develops a surrogate model for particle swarm optimisation based wrapper feature selection by selecting a small number of instances to create a surrogate training set. Furthermore, based on the surrogate model, we propose a sampling local search, which improves the current best solution by utilising information from the previous evolution- ary iterations. Experiments on 10 datasets show that the surrogate training set can reduce the computation time without affecting the classification performance. Meanwhile the sampling local search results in a significantly smaller number of features, especially on large datasets. The combination of the two proposed ideas successfully reduces the number of features and achieves better performance than using all features, a recent sequential fea- ture selection algorithm, original PSO, and PSO with one of them only on most datasets.



</p><p><strong>Title: Feature Selection in High Dimensional Data by a Filter-Based Genetic Algorithm
</strong><br/><strong>Author:</strong>  Claudio De Stefano, Franecsco Fontanella, Alessandra Scotto di Freca
</strong><br/><strong>Abstract:</strong> In classification and clustering problems, feature selection techniques can be used to reduce the dimensionality of the data and increase the performances.  However, feature selection is a challenging task, especially when hundred or thousands of features are involved. In this framework, we present a new approach for improving the performance of a filter-based genetic algorithm. The proposed approach consists of two steps: first, the available features are ranked according to a univariate evaluation function; then the search space represented by the first M features in the ranking is searched using  a filter-based genetic algorithm for finding feature subsets with a high discriminative power.Experimental results demonstrated the effectiveness of our approach in dealing with high dimensional data, both in terms of recognition rate and feature number reduction.



</p><p><strong>Title: Brain Programming and the Random Search in Object Categorization
</strong><br/><strong>Author:</strong>  Gustavo Olague, Eddie Clemente, Daniel E. Hernandez, Aaron Barrera
</strong><br/><strong>Abstract:</strong> Computational neuroscience lays the foundations of intelligent behavior through the application of machine learning approaches. Brain programming, which derives from such approaches, is emerging as a new evolutionary computing paradigm for solving computer vision and pattern recognition problems. Primate brains have several distinctive features that are obtained by a complex arrangement of highly interconnected and numerous cortical visual areas. This paper describes a virtual system that mimics the complex structure of primate brains composed of an artificial dorsal pathway -- or ``where" stream -- and an artificial ventral pathway -- or ``what" stream -- that are fused to recreate an artificial visual cortex. The goal is to show that brain programming is able to discover numerous heterogeneous functions that are applied within a hierarchical structure of our virtual brain. Thus, the proposal applies two key ideas: first, object recognition can be achieved by a hierarchical structure in combination with the concept of function composition; second, the functions can be discovered through multiple random runs of the search process. This last point is important since is the first step in any evolutionary algorithm; in this way, enhancing the possibilities for solving hard optimization problems.



</p><p><strong>Title:  Using Particle Swarm Optimisation and the Silhouette Metric to Estimate the Number of Clusters, Select Features, and Perform Clustering
</strong><br/><strong>Author:</strong>  Andrew Lensen, Bing Xue, Mengjie Zhang
</strong><br/><strong>Abstract:</strong> One of the most difficult problems in clustering, the task of grouping similar instances in a dataset, is automatically determining the number of clusters that should be created. When a dataset has a large number of attributes (features), this task becomes even more difficult due to the relationship between the number of features and the number of clusters produced. One method of addressing this is feature selection, the process of selecting a subset of features to be used. Evolutionary computation techniques have been used very effectively for solving clustering problems, but have seen little use for simultaneously performing the three tasks of clustering, feature selection, and determining the number of clusters. Furthermore, only a small number of existing methods exist, but they have a number of limitations that affect their performance and scalability. In this work, we introduce a number of novel techniques for improving the performance of these three tasks using particle swarm optimisation and statistical techniques. We conduct a series of experiments across a range of datasets with clustering problems of varying difficulty. The results show our proposed methods achieve significantly better clustering performance than existing methods, while only using a small number of features and automatically determining the number of clusters more accurately.



</p><p><strong>Title: Container Vessel Stowage Planning System using Genetic Algorithm
</strong><br/><strong>Author:</strong>  Miri Weiss Cohen, Vitor N. Coelho, Adi Dahan, Itzzik Kaspi
</strong><br/><strong>Abstract:</strong> This paper deals with the container stowage planning problem, an important and a complex problem in maritime logistic optimization. The variant tackled in this work involves several constraints, inspired by real-life problems and application found in the literature. Given the complexity of the problem, which belongs to the class of  NP hard problems, a novel evolutionary metaheuristic algorithm is developed and designed  considering the ability and flexibility of Genetic Algorithm (GA). The approach is based on a two-phase procedure, one for master planning and the other for allocation of the containers into slots.  GA parameters are analyzed to achieve practical and best results.The system offers stowage allocation solutions for both phases, thus offering flexibility for a wide variety of vessels and route combinations.



</p><p><strong>Title: The Artificial Immune Ecosystem: a bio-inspired meta-algorithm for boosting time series anomaly detection with expert input
</strong><br/><strong>Author:</strong>  Fabio Guigou, Pierre Collet, Pierre Parrend
</strong><br/><strong>Abstract:</strong> One of the challenges in machine learning, especially in the Big Data era, is to obtain labeled data sets. Indeed, the difficulty of labeling large amounts of data had lead to an increasing reliance on unsupervised classifiers, such as deep autoencoders. In this paper, we study the problem of involving a human expert in the training of a classifier instead of using labeled data. We use anomaly detection in network monitoring as a field of application. We demonstrate how using crude, already existing monitoring software as a heuristic to choose which points to label can boost the classification rate with respect to both the monitoring software and the classifier trained on a fully labeled data set, with a very low computational cost. We introduce the Artificial Immune Ecosystem meta-algorithm as a generic framework integrating the expert, the heuristic and the classifier.



</p><p><strong>Title: Empirical Analysis of Optimization Methods for the Real-World Dial-a-Ride Problem
</strong><br/><strong>Author:</strong>  Dilek Arikan, Cetin Oztoprak, Sanem Sariel
</strong><br/><strong>Abstract:</strong> This paper deals with solving the Dial-a-Ride Problem (DARP) for an on-demand delivery start-up company which delivers products to its customers from their corresponding pick-up points within guaranteed time intervals. The primary goal of the company is to minimize its operational costs while fulfilling the orders under the constraints on time window, duration, carrier capacity and ride time. This problem is formulated as the real-world DARP, and two methods are empirically evaluated by using Mixed Integer Programming (MIP) and Genetic Algorithm (GA) frameworks. The experiments are done on the simulated data provided by the company. The results show that a heuristic approach is more suitable for the real-world problem to meet the time window limitations.


</p><p><strong>Title: Presenting the ECO: Evolutionary Computation Ontology
</strong><br/><strong>Author:</strong>  Anil Yaman, Ahmed Hallawa, Matt Coler, Giovanni Iacca
</strong><br/><strong>Abstract:</strong> A well-established notion in Evolutionary Computation (EC) is the importance of the balance between exploration and exploitation. Data structures (e.g. for solution encoding), evolutionary operators, selection and fitness evaluation facilitate this balance. Furthermore, the ability of an Evolutionary Algorithm (EA) to provide efficient solutions typically depends on the specific type of problem. In order to obtain the most efficient search, it is often needed to incorporate any available knowledge (both at algorithmic and domain level) into the EA. In this work, we develop an ontology to formally represent knowledge in EAs. Our approach makes use of knowledge in the EC literature, and can be used for suggesting efficient strategies for solving problems by means of EC. We call our ontology "Evolutionary Computation Ontology" (ECO). In this contribution, we show one possible use of it, i.e. to establish a link between algorithm settings and problem types. We also show that the ECO can be used as an alternative to the available parameter selection methods and as a supporting tool for algorithmic design.



</p><p><strong>Title: A New Evolutionary Algorithm for Synchronization
</strong><br/><strong>Author:</strong>  Jakub Kowalski, Adam Roman
</strong><br/><strong>Abstract:</strong> A synchronizing word brings all states of a finite automaton to the one particular state. From practical reasons the synchronizing words should be as short as possible. Unfortunately, the decision version of the problem is NP-complete. In this paper we present a new evolutionary approach for finding possibly short synchronizing words for a given automaton. As the optimization problem has two contradicting goals (the word's length and the word's rank) we use a 2 population feasible-infeasible approach. It is based on the knowledge on words' ranks of all prefixes of a given word. This knowledge makes the genetic operators more efficient than in case of the standard letter-based operators.



</p><p><strong>Title: Large Scale Problems in Practice: The effect of dimensionality on the interaction among variables
</strong><br/><strong>Author:</strong>  Fabio Caraffini, Ferrante Neri, Giovanni Iacca
</strong><br/><strong>Abstract:</strong> This article performs a study on correlation between pairs of variables in dependence on the problem dimensionality. Two tests, based on Pearson and Spearman coefficients, have been designed and used in this work. In total, 86 test problems ranging between 10 and 1000 variables have been studied. If the most commonly used experimental conditions are used, the correlation between pairs of variables appears, from the perspective of the search algorithm, to consistently decrease. This effect is not due to the fact that the dimensionality modifies the nature of the problem but is a consequence of the experimental conditions: the computational feasibility of the experiments imposes an extremely shallow search in case of high dimensions. An exponential increase of budget and population with the dimensionality is still practically impossible. Nonetheless, since real-world application may require that large scale problems are tackled despite of the limited budget, an algorithm can quickly improve upon initial guesses if it integrates the knowledge that an apparent weak correlation between pairs of variables occurs, regardless the nature of the problem.


</p><p><strong>Title: A Framework for Knowledge Integrated Evolutionary Algorithms
</strong><br/><strong>Author:</strong>  Ahmed Hallawa, Anil Yaman, Giovanni Iacca, Gerd Ascheid
</strong><br/><strong>Abstract:</strong> One of the main reasons for the success of Evolutionary Algorithms (EAs) is their general-purposeness, i.e. the fact that they can be applied in a straight forward manner to a broad range of optimization problems, without any specific prior knowledge. On the other hand, it has been shown that incorporating a priori knowledge, such as expert knowledge or empirical findings, can significantly improve the performance of an EA. However, integrating knowledge in EAs poses numerous challenges. It is often the case that the features of the search space are unknown, hence any knowledge associated with the search space properties can be hardly used. In addition, a priori knowledge is typically problem-specific and hard to generalize. In this paper, we propose a framework, called Knowledge Integrated Evolutionary Algorithm (KIEA), which facilitates the integration of existing knowledge into EAs. Notably, the KIEA framework is EA-agnostic, i.e. it works with any evolutionary algorithm, problem-independent, i.e. it is not dedicated to a specific type of problems and expandable, i.e. its knowledge base can grow over time. Furthermore, the framework integrates knowledge while the EA is running, thus optimizing the consumption of computational power. In the preliminary experiments shown here, we observe that the KIEA framework produces in the worst case an 80\% improvement on the converge time, w.r.t. the corresponding ``knowledge-free'' EA counterpart.



</p><p><strong>Title: DICE: A New Family of Bivariate Estimation of Distribution Algorithms based on Dichotomised Multivariate Gaussian Distributions
</strong><br/><strong>Author:</strong>  Fergal Lane, R. Muhammad Atif Azad, Conor Ryan
</strong><br/><strong>Abstract:</strong> A new family of \emph{Estimation of Distribution Algorithms} (EDAs) for discrete search spaces is presented. The proposed algorithms, which we label DICE (\emph{D}iscrete \emph{C}orrelated \emph{E}stimation of distribution algorithms) are based, like previous bivariate EDAs such as MIMIC and BMDA, on bivariate marginal distribution models. However, bivariate models previously used in similar discrete EDAs were only able to exploit an $O(d)$ subset of all the $O(d^{2})$ bivariate variable dependencies between $d$ variables. We introduce, and utilize in DICE, a model based on \emph{dichotomised multivariate Gaussian distributions}. These models are able to capture and make use of all $O(d^{2})$ bivariate variable interactions in binary and multary search spaces. This paper tests the performances of these new EDA models and algorithms on a suite of challenging combinatorial optimization problems, and compares their performances to previously used discrete-space bivariate EDA models. EDAs utitilzing these new \emph{dichotomised Gaussian} (DG) models exhibit significantly superior optimization performances, with the performance gap becoming more marked with increasing dimensionality.



</p><p><strong>Title: Ranking programming languages for evolutionary algorithm operations

</strong><br/><strong>Author:</strong>  JJ Merelo, Israel Blancas-Álvarez, Gustavo Romero, Pedro Castillo, Pablo García Sánchez, Víctor Rivas, Mario García-Valdez, Amaury Hernández-Águila, Mario Román
</strong><br/><strong>Abstract:</strong> In this paper we measure the speed of several popular and recent
programming languages performing the most usual operators in the
canonical evolutionary algorithm, mutation and crossover, as well as
an usual fitness function, OneMax, which is representative of the kind
of operations performed in binary chromosomes. Our main objective is,
first, to create programs in programming languages that use the
fastest implementation available available. Second, to find out the differences in speeds for the different languages. Third, to find out whether the usual
assumptions about the speed of languages really holds. And, finally, to
find if the assumed order of speed in languages used in evolutionary
algorithms holds true for all kinds of operations. In order to do that,
we use available implementations or perform our own, concluding that
the evolutionary algorithm scenario is more complex than usually
assumed and finding out some surprising {\em winners} and {\em losers} among the
languages tested.



</p><p><strong>Title: Distance-based tournament selection
</strong><br/><strong>Author:</strong>  Christian Oesch
</strong><br/><strong>Abstract:</strong> In this paper we analyze the performance of a novel genetic selection mechanism based on the classic tournament selection. This method tries to utilize the information present in the solution space of individuals, before mapping their solutions to a fitness measure. This allows to favour individuals dependent on what state the evolutionary search is in. If a population is caught up in several local optima, the correlation of the distance between the individuals and their performance tends to be lower than when the population converges to a single global optimum. We utilize this information by structuring the tournaments in a way favorable to each situation. The results of the experiments suggest that this new selection method is beneficial.



</p><p><strong>Title: Preferences-Based Choice Prediction in Evolutionary Multi-Objective Optimization
</strong><br/><strong>Author:</strong>  Manish Aggarwal, Justin Heinermann, Stefan Oehmcke, Oliver Kramer
</strong><br/><strong>Abstract:</strong> Evolutionary multi-objective algorithms (EMOAs) of the type of NSGA-2 approximate the Pareto-front, after which a decision-maker (DM) is confounded with the primary task of selecting the best solution amongst all the equally good solutions on the Pareto-front. In this paper, we complement the popular NSGA-2 EMOA by posteriori identifying a DM's best solution among the candidate solutions on the Pareto-front, generated through NSGA-2. To this end, we employ a preference-based learning approach to learn an abstract ideal reference point of the DM on the multi-objective space, which reflects the compromises the DM makes against a set of conflicting objectives. The solution that is closest to this reference-point is then predicted as the DM's best solution. The pairwise comparisons of the candidate solutions provides the training information for our learning model. The experimental results on ZDT1 dataset shows that the proposed approach is not only intuitive, but also easy to apply, and robust to inconsistencies in the DM's preference statements.



</p><p><strong>Title: Numerical optimization of ESA's Messenger space mission benchmark
</strong><br/><strong>Author:</strong>  Martin Schlueter, Mohammed Wahib, Masaharu Munetomo
</strong><br/><strong>Abstract:</strong> The design and optimization of interplanetary space mission trajectories is known to be a difficult challenge. The trajectory of the Messenger mission (launched by NASA in 2004) is one of the most complex ones ever created. The European Space Agency (ESA) makes available a numerical optimization benchmark which resembles an accurate model of Messengers full mission trajectory. This contribution presents an optimization approach which is capable to (robustly) solve ESA's Messenger full mission benchmark to its putative global solution within 24 hours run time on a moderate sized computer cluster. The considered algorithm, named MXHPC, is a parallelization framework for the MIDACO optimization algorithm which is an evolutionary method particularly suited for space trajectory design. The presented results demonstrate the effectiveness of evolutionary computing for complex real-world problems which have been previously considered intractable.


</p><p><strong>Title: A VNS with Parallel Evaluation of Solutions for the Inverse Lighting Problem
Ignacio Decia, Rodrigo Leira, Martín Pedemonte, Eduardo Fernández, Pablo Ezzatti
</strong><br/><strong>Abstract:</strong> Lighting design is a key issue in architectural design. The Inverse Lighting Problem (ILP) is an optimization problem that arises in lighting design and consist in finding the best configuration of lights that meets a set of goals that designers would like to achieve. In this paper, we present three different VNS that evaluate several solutions in parallel, improving the performance of a traditional VNS that has already been proposed for solving the ILP. These methods exploit the block matrix multiplication algorithms in order to increase the computational intensity of the algorithm and are specially well suited for parallel computation in GPUs architectures. The experimental analysis performed in two CPU/GPU hardware platforms for two scenarios with different complexity shows that the proposed methods provide fast results and are able to allow the interactive lighting design.



</p><p><strong>Title: Evolving Cut-off Mechanisms and other Work-Stealing Parameters for Parallel Programs
</strong><br/><strong>Author:</strong>  Alcides Fonseca, Nuno Lourenço, Bruno Cabral
</strong><br/><strong>Abstract:</strong> Optimizing parallel programs is a complex task because the interference among many different parameters. Work-stealing runtimes, used to dynamically balance load among different processor cores, are no exception. This work explores the automatic configuration of the following runtime parameters: dynamic granularity control algorithms, granularity control cache, work-stealing algorithm, lazy binary splitting parameter, the maximum queue size and the unparking interval. The performance of the program is highly sensible to the granularity control algorithm, which can be a combination of other granularity algorithms.In this work, we address two search-based problems: finding a globally efficient work-stealing configuration, and finding the best configuration just for an individual program. For both problems, we propose the use of a Genetic Algorithm (GA). The genotype of the GA is able to represent combinations of up to three cut-off algorithms, as well as other work-stealing parameters. The proposed GA has been evaluated in its ability to obtain a more efficient solution across a set of programs, in its ability to generalize the solution to a larger set of programs, and its ability to evolve single programs individually. The GA was able to improve the performance of the set of programs in the training set, but the obtained configurations were not generalized to a larger benchmark set. However, it was able to successfully improve the performance of each program individually.



</p><p><strong>Title: Issues on GPU Parallel Implementation of Evolutionary High-dimensional Multi-objective Feature Selection
</strong><br/><strong>Author:</strong>  Juan José Escobar, Julio Ortega, Jesús González, Miguel Damas, Beatriz Prieto
</strong><br/><strong>Abstract:</strong> The interest on applications that analyse large volumes of high dimensional data has grown recently. Many of these applications related to the so-called Big Data show different implicit parallelism that can benefit from the efficient use, in terms of performance and power consumption, of Graphics Processing Unit (GPU) accelerators. Although the GPU microarchitectures make possible the acceleration of applications by exploiting parallelism at different levels, the characteristics of their memory hierarchy and the location of GPUs as coprocessors require a careful organization of the memory access patterns and data transferences to get efficient speedups. This paper aims to take advantage of heterogeneous parallel codes on GPUs to accelerate evolutionary approaches in Electroencephalogram (EEG) classification and feature selection in the context of Brain Computer Interface (BCI) tasks. The results show the benefits of taking into account not only the data parallelism achievable by GPUs, but also the memory access patterns, in order to increase the speedups achieved by superscalar cores.



</p><p><strong>Title: Embedded Grammars for Grammatical Evolution on GPGPU
Jose Ignacio Hidalgo, Carlos Cervigón, Jose Manuel Velasco
</strong><br/><strong>Author:</strong>  Jose Ignacio Hidalgo, Carlos Cervigón, Jose Manuel Velasco, Jose Manuel, Carlos García-Sánchez, Guillermo Botella
</strong><br/><strong>Abstract:</strong> This paper presents an implementation of Grammatical Evolution on a GPU architecture. Our proposal, \textit{Embedded Grammars}, implements the grammar directly in the code. Although more rigid, it allows to compute the decodification in parallel with the evaluation of the individuals. We tested three different grammars  with a set of eight symbolic regression problems.  The symbolic regression problems consists on obtaining a mathematical expression in the form $y=f(x)$, in our case, from a set of 288 pairs $x, y$. The analysis of the results shows that \textit{Embedded Grammars} are better not only in terms of execution time, but also in quality when compared with an implementation on a CPU. Speed-up results are also better than those presented in the literature.



</p><p><strong>Title: A performance assessment of evolutionary algorithms in volunteer computing environments: the importance of entropy
</strong><br/><strong>Author:</strong>  Paloma de las Cuevas, Pablo Garcia Sanchez, Mario Garcia?a-Valdez, Juan J. Merelo Guervós 
</strong><br/><strong>Abstract:</strong>  In a volunteer distributed computing system, users run a program on their own machine to contribute to a common effort. If the program is embedded in a web page, collaboration is straightforward, but also ephemeral. In this paper, we analyze a volunteer evolutionary computing system called NodIO, by running several experiments, some of them massive. Our objective is to discover rules that encourage volunteer participation and also the interplay of these contributions with the dynamics of the algorithm itself, making it efficient enough. We will show different measures of participation and contribution to the algorithm, as well as how different volunteer usage patterns and tweaks in the algorithm, such as restarting clients when a solution has been found, contribute to improvements and leveraging of these contributions. We will also try to find out what is the key factor in the early termination of the experiments, measuring entropy in the contributions and other large scale indicators.



</p><p><strong>Title: Overcoming Initial Convergence in Multi-Objective Evolution of Robot Control and Morphology Using a Two-Phase Approach
</strong><br/><strong>Author:</strong>  Tønnes F. Nygaard, Eivind Samuelsen, Kyrre Glette
</strong><br/><strong>Abstract:</strong> Co-evolution of robot morphologies and control systems is a new and interesting approach for robotic design. However, the increased size and ruggedness of the search space becomes a challenge, often leading to early convergence with sub-optimal morphology-controller combinations. Further, mutations in the robot morphologies tend to cause large perturbations in the search, effectively changing the environment, from the controller's perspective. In this paper, we present a two-stage approach to tackle the early convergence in morphology-controller co-evolution. In the first phase, we allow free evolution of morphologies and controllers simultaneously, while in the second phase we re-evolve the controllers while locking the morphology. The feasibility of the approach is demonstrated in physics simulations, and later verified on three different real-world instances of the robot morphologies. The results demonstrate that by introducing the two-phase approach, the search produces solutions which outperform the single co-evolutionary run by over 10%.



</p><p><strong>Title: Evolutionary Adaptation to Social Information Use without Learning
</strong><br/><strong>Author:</strong>  James M. Borg, Alastair Channon
</strong><br/><strong>Abstract:</strong> Social information can provide information about the presence, state and intentions of other agents; therefore it follows that the use of social information may be of some adaptive benefit. As with all information, social information must be interpretable and relatively accurate given the situation in which it is derived. In both nature and robotics, agents learn which social information is relevant and under which circumstances it may be relied upon to provide useful information about the current environmental state. However, it is not clear to what extent social information alone is beneficial when decoupled from a within-lifetime learning process, leaving evolution to determine whether social information provides any long term adaptive benefits. In this work we assess this question of the adaptive value of social information when it is not accompanied by a within-lifetime learning process. The aim here is to begin to understand when social information, here expressed as a form of public information, is adaptive; the rationale being that any social information that is adaptive without learning will be a good base to allow the learning processes associated with social information to evolve and develop later. Here we show, using grounded neuroevolutionary artificial life simulations incorporating simulated agents, that social information can in certain circumstances provide an adaptive advantage to agents, and that social information that more accurately indicates success confers more reliable information to agents leading to improved success over less reliable sources of social information. 


</p><p><strong>Title: Interactive Evolution of Complex Behaviours through Skill Encapsulation
</strong><br/><strong>Author:</strong>  Pablo González de Prado Salas, Sebastian Risi
</strong><br/><strong>Abstract:</strong> Human-based computation (HBC) is an emerging research area in which humans and machines collaborate to solve tasks that neither one can solve in isolation. In evolutionary computation, HBC is often realized through interactive evolutionary computation (IEC), in which a user guides evolution by iteratively selecting the parents for the next generation. IEC has shown promise in a variety of different domains, but evolving more complex or hierarchically composed behaviours remains challenging with the traditional IEC approach. To overcome this challenge, this paper combines the recently introduced ESP algorithm with IEC to allow users to intuitively break complex challenges into smaller pieces and preserve, reuse and combine interactively evolved sub-skills. The combination of ESP principles with IEC provides a new way in which human insights can be leveraged in evolutionary computation and, as the results in this paper show, IEC-ESP is able to solve complex control problems that are challenging for a traditional fitness-based approach.



</p><p><strong>Title: Evolution and Morphogenesis of Simulated Modular Robots: A Comparison Between a Direct and Generative Encoding
</strong><br/><strong>Author:</strong>  Frank Veenstra, Andres Faina, Sebastian Risi, Kasper Stoy
</strong><br/><strong>Abstract:</strong> Modular robots offer an important benefit in evolutionary robotics, which is to quickly evaluate evolved morphologies and control systems in reality. However, artificial evolution of simulated modular robotics is a difficult and time consuming task requiring significant computational power.  While artificial evolution in virtual creatures has made use of powerful generative encodings, here we investigate how a generative encoding and direct encoding compare for the evolution of locomotion in modular robots when the number of robotic modules changes. Simulating less modules would decrease the size of the genome of a direct encoding while the size of the genome of the implemented generative encoding stays the same. We found that the generative encoding is significantly more efficient in creating robot phenotypes in the initial stages of evolution when simulating a maximum of 5, 10, and 20 modules. This not only confirms that generative encodings lead to decent performance more quickly, but also that when simulating just a few modules a generative encoding is more powerful than a direct encoding for creating robotic structures. Over longer evolutionary time, the difference between the encodings no longer becomes statistically significant. This leads us to speculate that a combined approach -- starting with a generative encoding and later implementing a direct encoding -- can lead to more efficient evolved designs. 


</p><p><strong>Title: Continual and One-Shot Learning through Neural Networks with Dynamic External Memory
</strong><br/><strong>Author:</strong>  Benno Lüders, Mikkel Schläger, Aleksandra Korach, Sebastian Risi
</strong><br/><strong>Abstract:</strong> Training neural networks to quickly learn new skills without forgetting previously learned skills is an important open challenge in machine learning. A common problem for adaptive networks that can learn during their lifetime is that the weights encoding a particular task are often overridden when a new task is learned. This paper takes a step in overcoming this limitation by building on the recently proposed Evolving Neural Turing Machine (ENTM) approach. In the ENTM, neural networks are augmented with an external memory component that they can write to and read from, which allows them to store associations quickly and over long periods of time. The results in this paper demonstrate that the ENTM is able to perform one-shot learning in  reinforcement learning tasks without catastrophic forgetting of previously stored associations. Additionally, we introduce a new ENTM default jump mechanism that makes it easier to find unused memory location and therefor facilitates the evolution of continual learning networks. Our results suggest that augmenting evolving networks with an external memory component is not only a viable mechanism for adaptive behaviors in neuroevolution but also allows these networks to perform continual and one-shot learning at the same time.



</p><p><strong>Title: Hybrid Algorithms Based on Integer Programming for the Search of Prioritized Test Data in Software Product Lines
</strong><br/><strong>Author:</strong>  Javier Ferrer, Francisco Chicano, Enrique Alba
</strong><br/><strong>Abstract:</strong> In Software Product Lines (SPLs) it is not possible, in general, to test all products of the family. The number of products denoted by a SPL is very high due to the combinatorial explosion of features. For this reason, some coverage criteria have been proposed which try to test at least all feature interactions without the necessity to test all products, e.g., all pairs of features (pairwise coverage). In addition, it is desirable to first test products composed by a set of priority features. This problem is known as the Prioritized Pairwise Test Data Generation Problem. In this work we propose two hybrid algorithms using Integer Programming (IP) to generate a prioritized test suite. The first one is based on an integer linear formulation and the second one is based on a integer quadratic (nonlinear) formulation. We compare these techniques with two state-of-the-art algorithms, the Parallel Prioritized Genetic Solver (PPGS) and a greedy algorithm called prioritized-ICPL. Our study reveals that our hybrid nonlinear approach is clearly the best in both, solution quality and computation time. Moreover, the nonlinear variant (the fastest one) is 27 and 42 times faster than PPGS in the two groups of instances analyzed in this work.


</p><p><strong>Title: On the Use of Smelly Examples to Detect Code Smells in JavaScript
</strong><br/><strong>Author:</strong>  Ian Shoenberger, Wiem Mkaouer, Marouane Kessentini
</strong><br/><strong>Abstract:</strong> JavaScript has become one of the widely-used languages. However, as the size of JavaScript-based applications grows, the number of defects grows as well. Re-cent studies have produced a set of manually defined rules to identify these de-fects. We propose, in this work, the automation of deriving these rules to ensure scalability and potentially the detection of a wider set of defects without requiring any extensive knowledge on rules tuning. To this end, we rely on a base of exist-ing code smells that is used to train the detection rules using Genetic Program-ming and find the best threshold of metrics composing the rules. The evaluation of our work on 9 JavaScript web projects has shown promising results in terms of detection precision of 92% and recall of 85%, with no threshold tuning re-quired.



</p><p><strong>Title: Deep Parameter Tuning of Concurrent Divide and Conquer Algorithms in Akka
</strong><br/><strong>Author:</strong>  David White, Leonid Joffe, Edward Bowles, Jerry Swan
</strong><br/><strong>Abstract:</strong> Akka is a widely-used high-performance and distributed computing toolkit for fine-grained concurrency, written in Scala for the Java Virtual Machine. Although Akka elegantly simplifies the process of building complex parallel software, many crucial decisions that affect system performance are deferred to the user. Employing the method of Deep Parameter Tuning to extract embedded `magic numbers' from source code, we use the CMA-ES evolutionary computation algorithm to optimise the concurrent implementation of three widely-used divide-and-conquer algorithms within the Akka toolkit: Quicksort, Strassen's matrix multiplication, and the Fast Fourier Transform. 


</p><p><strong>Title: Focusing Learning-based Testing away from Known Weaknesses
</strong><br/><strong>Author:</strong>  Christian Fleischer, Jörg Denzinger
</strong><br/><strong>Abstract:</strong> We present an extension to learning-based testing of systems for adversary-induced weaknesses that addresses the problem of repeated generation of known weaknesses. Our approach adds to the normally used fitness measure a component that computes the similarity of a test to known tests that revealed a weakness and uses this similarity to penalize new tests.  We instantiated this idea to the testing of ad-hoc wireless networks using the IACL approach, more precisely to applications in precision agriculture, and our experiments show that our modification results in finding substantially different tests from the test(s) that we want to avoid.



</p><p><strong>Title: Polytypic Genetic Programming
</strong><br/><strong>Author:</strong>  Jerry Swan, Krzysztof Krawiec, Neil Ghani
</strong><br/><strong>Abstract:</strong> The application of search-based techniques (e.g. Genetic Programming (GP) or Genetic Improvement (GI)) to programs often requires a great deal of `boilerplate' code to adapt the application APIs to the search mechanism. In addition, the majority of existing approaches are not type-safe: i.e. they can fail at runtime because the search mechanisms lack strict type information often available to the compiler. This is clearly an obstacle to widespread acceptance for dynamically optimized programs --- one of the stated aims of contemporary research in Search-Based Software Engineering (SBSE). In this article, we describe Polytope, a Scala framework that uses polytypic programming, a relatively recent advance in program abstraction. Polytope requires a minimum of boilerplate code and supports a form of strong-typing in which type rules are automatically enforced by the compiler, even for search operations such as mutation which are applied at runtime. By operating directly on language-native expressions, it provides an embeddable optimization procedure for existing code. It can therefore be seen as occupying an intermediate position between GP and (online) GI, with the potential to ease the path to adoption of Genetic Improvement. We give a tutorial example of our specific polytypic approach and  compare both runtime efficiency and required lines of code against the well-known EpochX GP framework, showing comparable performance in the former and the complete elimination of boilerplate for the latter.


</p><p><strong>Title: Evolving rules for action selection in automated testing via genetic programming - a first approach 
</strong><br/><strong>Author:</strong>  Anna I. Esparcia-Alcazar, Francisco Almenar, Urko Rueda, Tanja E.J. Vos
</strong><br/><strong>Abstract:</strong>  Tools that perform automated software testing via the user interface rely on an action selection mechanism that at each step of the testing process decides what to do next. This mechanism is  often based on random choice, a practice commonly referred to as monkey testing.  In this work we evaluate a first approach to genetic programming (GP) for action selection that involves evolving IF-THEN-ELSE rules; we carry out experiments  and compare the results with those obtained by random selection and also by Q-learning, a reinforcement learning technique. Three applications are used as Software Under Test (SUT) in the experiments, two of which are proprietary desktop applications and the other one an open source web-based application.



</p><p><strong>Title: A new multi-swarm particle swarm optimization for robust optimization over time
</strong><br/><strong>Author:</strong>  Danial Yazdani, Trung Thanh Nguyen, Juegen Branke, Jin Wang
</strong><br/><strong>Abstract:</strong> Dynamic optimization problems (DOPs) are optimization problems that change over time, and most investigations in this area focus on tracking the moving op-timum efficiently. However, continuously tracking a moving optimum is not practical in many real-world problems because changing solutions frequently is not possible or very costly. Recently, another practical way to tackle DOPs has been suggested: robust optimization over time (ROOT). In ROOT, the main goal is to find solutions that can remain acceptable over an extended period of time. In this paper, a new multi-swarm PSO algorithm is proposed in which different swarms track peaks and gather information about their behavior. This information is then used to make decisions about the next robust solution. The main goal of the proposed algorithm is to maximize the average number of environments dur-ing which the selected solutionsí quality remains acceptable. The experimental re-sults show that our proposed algorithm can perform significantly better than ex-isting work in this aspect.



</p><p><strong>Title: The Static and Stochastic VRP with Time Windows and both random Customers and Reveal Times
</strong><br/><strong>Author:</strong>  Michael Saint-Guillain, Christine Solnon, Yves Deville
</strong><br/><strong>Abstract:</strong> Static and stochastic vehicle routing problems (SS-VRP) aim at modeling and solving real life problems by considering uncertainty on the data. In particular, customer data may not be known with certainty. Before the beginning of the day, probability distributions on customer data are used to compute a first-stage solution that optimizes an expected cost. Customer data are revealed online, while the solution is executed, and a recourse strategy is applied on the first-stage solution to quickly adapt it. Existing SS-VRP variants usually make a strong assumption on the time at which a stochastic customer reveals its data  ({\em e.g.}, when a vehicle arrives at the corresponding location). We introduce a new SS-VRP where customer reveal times are stochastic. We define first-stage solutions and a recourse strategy for this new problem. A key point is to introduce waiting locations that are used in the first stage-solution to wait for the realization of customer stochastic data. We show how to compute the expected cost of a first-stage solution in pseudo polynomial time, in the particular case where the vehicles are not constrained by a maximal capacity. We also introduce a local search-based approach for optimizing the first-stage solution, and introduce a {\em scale} parameter to tune the precision and cost of the expected cost computation. Experimental results on small to large instances demonstrate its efficiency and flexibility.



</p><p><strong>Title: Pre-Scheduled Colony Size Variation in Dynamic Environments
</strong><br/><strong>Author:</strong>  Michalis Mavrovouniotis, Anastasia Ioannou, Shengxiang Yang
</strong><br/><strong>Abstract:</strong> The performance of theMAX-MIN ant system (MMAS) in dynamic optimization problems (DOPs) is sensitive to the colony size. In particular, a large colony size may waste computational resources whereas a small colony size may restrict the searching capabilities of the algorithm. There is a trade off in the behaviour of the algorithm between the early and later stages of the optimization process. A smaller colony size leads to better performance on shorter runs whereas a larger colony size leads to better performance on longer runs. In this paper, pre-scheduling of varying the colony size of MMAS is investigated in dynamic environments.



</p><p><strong>Title: An online packing heuristic for the three-dimensional container loading problem in dynamic environments and the Physical Internet
</strong><br/><strong>Author:</strong>  Chi Trung Ha, Trung Thanh Nguyen, Lam Thu Bui, Ran Wang
</strong><br/><strong>Abstract:</strong> In this paper, we consider the online three-dimensional container loading problem. We develop a novel online packing algorithm to solve the three-dimensional bin packing problem in the online case where items are not known well in advance and they have to be packed in real-time when they arrive. This is relevant in many real-world scenarios such as automated cargo loading in warehouses. This is also relevant in the new logistics model of Physical Internet. The effectiveness of the online packing heuristic is evaluated on a set of generated data. The experimental results show that the algorithm could solve the 3D container loading problems in online fashion and is competitive against other algorithms both in the terms of running time, space utilization and the number of bins.



</p><p><strong>Title: Advancing Dynamic Evolutionary Optimization Using In-Memory Database Technology
Julia Jordan, Wei Cheng, Bernd Scheuermann
</strong><br/><strong>Abstract:</strong> This paper reports on IMDEA (In-Memory database Dynamic Evolutionary Algorithm), an approach to dynamic evolutionary optimization exploiting in-memory database (IMDB) technology to expedite the search process subject to change events arising at runtime. The implemented system benefits from optimization knowledge persisted on an IMDB serving as associative memory to better guide the optimizer through changing environments. For this, specific strategies for knowledge processing, extraction and injection are developed and evaluated. Moreover, prediction methods are embedded and empirical studies outline to which extent these methods are able to anticipate forthcoming dynamic change events by evaluating historical records of previous changes and other optimization knowledge managed by the IMDB. 


</p><p><strong>Title: Road Traffic Rules Synthesis using Grammatical Evolution
</strong><br/><strong>Author:</strong>  Eric Medvet, Alberto Bartoli, Jacopo Talamini
</strong><br/><strong>Abstract:</strong> We consider the problem of the automatic synthesis of road traffic rules, motivated by a future scenario in which human and machine-based drivers will coexist on the roads: in that scenario, current road rules may be either unsuitable or inefficient. We approach the problem using Grammatical Evolution (GE). To this end, we propose a road traffic model which includes concepts amenable to be regulated (e.g., lanes, intersections) and which allows drivers to temporarily evade traffic rules when there are no better alternatives. In our GE framework, each individual is a set of rules and its fitness is a weighted sum of traffic efficiency and safety, as resulting from a number of simulations where all drivers are subjected to the same rules. Experimental results show that our approach indeed generates rules leading to a safer and more efficient traffic than enforcing no rules or rules similar to those currently used.


</p><p><strong>Title: Solving Dynamic Graph Coloring Problem Using Dynamic Pool Based Evolutionary Algorithm
</strong><br/><strong>Author:</strong>  Betul Boz, Gizem Sungu
</strong><br/><strong>Abstract:</strong> Graph coloring problem is one of the main optimization problems from the literature. Many real world problems interacting with changing environments can be modeled with dynamic graphs. Genetic algorithms are a good choice to solve dynamic graph coloring problem because they can adopt to dynamic environments and are suitable for problems with NP-hard complexity. In this paper, we propose a dynamic pool based evolutionary algorithm (DPBEA) for solving the dynamic graph coloring problem, which contains a partition based representation to adopt to the dynamic changes of the graph and carry the valuable information obtained in history. The proposed algorithm uses a novel special purpose pool based crossover operator that targets to minimize the number of colors used in the solutions and a local search method that tries to increase the diversity of the solutions. We compared the performance of our algorithm with a well known heuristic for solving the graph coloring problem and a genetic algorithm with a dynamic population using a large number of dynamic graphs. The experimental evaluation indicates that our algorithm outperforms these algorithms with respect to number of colors used by the algorithms in most of the test cases provided.



</p><p><strong>Title: Meta-Heuristics for Improved RF Emitter Localization
</strong><br/><strong>Author:</strong>  Sondre Andreas Engebraaten, Jonas Moen, Kyrre Glette
</strong><br/><strong>Abstract:</strong> Locating RF emitters can be done with a number of methods, but cheap and widely available sensors make the Power Difference of Arrival (PDOA) technique a prominent choice. Predicting the location of an unknown RF emitter can be seen as a continuous optimization problem, minimizing the error w.r.t. the sensor measurements gathered. Most instances of this problem feature multi-modality, making these challenging to solve. This paper presents an analysis of the performance of evolutionary computation and other meta-heuristic methods on this real-world problem. We applied the Nelder-Mead method, Genetic Algorith, Covariance Matrix Adaptation Evolutionary Strategies, Particle Swarm Optimization and Differential Evolution. The use of meta-heuristics solved the minimization problem more efficiently and precisely, compared to brute force search, potentially allowing for a more widespread use of the PDOA method. To compare algorithms two different metrics were proposed: average distance miss and median distance miss, giving insight into the algorithms' performance. Finally, the use of an adaptive mutation step proved important.



</p><p><strong>Title: Automated Design of Genetic Programming Classification Algorithms using a Genetic Algorithm
</strong><br/><strong>Author:</strong>  Thambo Nyathi, Nelishia Pillay  
</strong><br/><strong>Abstract:</strong>  There is a large scale initiative by the machine learning community to automate the design of machine learning techniques to remove reliance on the human expert, providing out of the box software that can be used by novices. In this study the automated design of genetic programming classification algorithms is proposed. A number of design decisions have to be considered by algorithm designers during the design process and this is usually a time consuming task. Our automated design approach uses a genetic algorithm to automatically configure a genetic programming classification algorithm. The genetic algorithm determines parameter values and sets the flow control for the classification algorithm. The proposed system is tested on real world problems and the results indicate that induced classifiers perform better than manually designed classifiers.


<!--
    <h2>EvoAPPLICATIONS 2016 – abstracts and programme</h2>
    <a name="INDUSTRIALAPPLICATIONS"></a>
    <h3> EvoAPPS 1 : INDUSTRIAL APPLICATIONS, WED 11:20-13:00
(APPs topics: GAMES+STOC)</h3>



<a name="STOCHASTICANDDYNAMICENVIRONMENTS"></a>
<h3>EvoAPPS 2 : STOCHASTIC AND DYNAMIC ENVIRONMENTS, WED 14:15-15:55
(APPs topics: STOC+COMPLEX)</h3>



<a name="COMPLEXSYSTEMS"></a>
<h3>EvoAPPS 3 : COMPLEX SYSTEMS, WED 16:20-18:00
(APPs topics: COMPLEX+FIN)</h3>


<a name="POSTERS"></a>
<h3>EVOAPPS POSTERS, WED 18:00 - 19:30</h3>


<a name="PATTERNRECOGNITION"></a>
<h3>EvoAPPS 4 : PATTERN RECOGNITION, THURS 09:30-11:10
(APPs topics: IASP+NUM)</h3>

<a name="GAMEAGENTS"></a>
<h3>EvoAPPS 5 : GAME AGENTS, THURS 11:35-13:15
(APPs topics: GAMES+STOC)</h3>


<a name="COMPUTERVISION"></a>
<h3>EvoAPPS 6 : COMPUTER VISION, THURS 11:35-13:15
(APPs topic: IASP)</h3>


<a name="CONTENTGENERATIONANDLEARNINGINGAMES"></a>
<h3>
EvoAPPS 7 : CONTENT GENERATION AND LEARNING IN GAMES, THURS 14:30-16:10
(APPs topic: GAMES)</h3>

<a name="COMMUNICATIONNETWORKS"></a>
<h3>EvoAPPS 8 : COMMUNICATION NETWORKS, THURS 14:30-16:10
(APPs topic: COMNET)</h3>

<a name="ROBOTICS"></a>
<h3>EvoAPPS 9 : ROBOTICS, THURS 16:30-18:10
(APPs topic: ROBOT)</h3>

<a name="RISKMANAGEMENTANDSECURITY"></a>
<h3>EvoAPPS 10 : RISK MANAGEMENT AND SECURITY, THURS 16:30-18:10
(APPs topics: COMNET+RISK)</h3>

<a name="ENERGYFINANCE"></a>
<h3>EvoAPPS 11 : ENERGY/FINANCE, FRI 09:30-11:10
(APPs topics: ENERGY+FIN)</h3>

<a name="CONTINUOUSPARAMETEROPTIMISATION"></a>
<h3>EvoAPPS 12 : CONTINUOUS PARAMETER OPTIMISATION, FRI 09:30-11:10
(APPs topics: NUM+STOC)</h3>
-->

 <h3>PUBLICATION DETAILS</h3>
    <p>Accepted papers will appear in the proceedings of Evo<span class="red">Star</span>, 
      published in a volume of the Springer Lecture Notes in Computer Science, 
      which will be available at the Conference.Submissions must be original and 
      not published elsewhere. The submissions will be peer reviewed by at least 
      three members of the program committee. The authors of accepted papers will 
      have to improve their paper on the basis of the reviewers comments and will 
      be asked to send a camera ready version of their manuscripts. At least one 
      author of each accepted work has to register for the conference and attend 
      the conference and present the work.The reviewing process will be double-blind, 
      please omit information about the authors in the submitted paper. </p>
    <h2>Submission Details</h2>
    <p>Submissions must be original and not published elsewhere. They will be 
      peer reviewed by members of the program committee. The reviewing process 
      will be double-blind, so please omit information about the authors in the 
      submitted paper. </p>
    <p>Submit your manuscript in <a href="http://www.springer.com/computer/lncs?SGWID=0-164-6-793341-0">Springer 
      LNCS format</a>. </p>
    <p> Please provide up to five keywords in your Abstract</p>
    <p>Page limit: 16 pages.<span> 
      </span></p>
    <strong>Submission link:</strong>  <a href="https://myreview.saclay.inria.fr/evoapps17/">https://myreview.saclay.inria.fr/evoapps17/</a>


 <?php include('footer.php') ?>
